# -*- coding: utf-8 -*-
"""deforestation_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zTRpznVGi32iNFTGpEqiz83ofnhMAxNp
"""

!pip install tensorflow Pillow scikit-learn matplotlib
!pip install tensorflow
!pip install albumentations
!pip install numpy pandas
!pip install geopandas rasterio
!pip install folium
!pip install --upgrade Pillow
!pip list

import os
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

deforested_dir = "/content/dataset/deforestation"
no_deforested_dir = "/content/dataset/no_deforestation"

img_height, img_width = 128, 128
input_shape = (img_height, img_width, 3)

def load_and_preprocess_images(directory, label):
    images = []
    labels = []
    for filename in os.listdir(directory):
        if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):
            img_path = os.path.join(directory, filename)
            try:
                img = Image.open(img_path).convert('RGB')
                img = img.resize((img_height, img_width))
                img_array = np.array(img) / 255.0
                images.append(img_array)
                labels.append(label)
            except Exception as e:
                print(f"Error processing image {filename}: {e}")
    return np.array(images), np.array(labels)

deforested_images, deforested_labels = load_and_preprocess_images(deforested_dir, 1)
no_deforested_images, no_deforested_labels = load_and_preprocess_images(no_deforested_dir, 0)

all_images = np.concatenate((deforested_images, no_deforested_images), axis=0)
all_labels = np.concatenate((deforested_labels, no_deforested_labels), axis=0)

X_train, X_test, y_train, y_test = train_test_split(
    all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels
)

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(1, activation="sigmoid"),
    ]
)

model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

epochs = 10
batch_size = 32
history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)

loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

model.save("/content/deforestation_classifier.h5")

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()